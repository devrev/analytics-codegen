# Input

Generate 10 moderately-complex SQL queries from the following table names/schema:

Table name: memory.aws_daily_cost_v7
Table schema: service VARCHAR env VARCHAR region VARCHAR usage_date DATE cost DOUBLE
Table name: memory.openai_daily_costs_v3
Table schema: usage_date DATE project_name VARCHAR amount INTEGER
Table name: memory.email_and_linkedin_chats
Table schema: id VARCHAR created_date TIMESTAMP subject VARCHAR sender_address VARCHAR sender_user_id VARCHAR receiver_address VARCHAR[] receiver_user_id VARCHAR[] cc_address VARCHAR[] cc_user_id VARCHAR[]
Table name: system.user_sessions_track_events_summary_v2
Table schema: rev_oid VARCHAR total_user_sessions BIGINT total_session_length DOUBLE is_verified BOOLEAN total_events BIGINT created_at TIMESTAMP
Table name: system.dim_incident
Table schema: object_type VARCHAR stock_schema_fragment VARCHAR playbook_ids VARCHAR[] subtype VARCHAR stock_schema_fragment_id VARCHAR mitigated_date TIMESTAMP actual_close_date TIMESTAMP severity_json VARCHAR id VARCHAR state VARCHAR resolved_at TIMESTAMP custom_fields VARCHAR pia_ids VARCHAR[] stakeholders VARCHAR[] stage_json VARCHAR operation VARCHAR modified_date TIMESTAMP display_id VARCHAR applies_to_part_ids VARCHAR[] artifact_ids VARCHAR[] impact VARCHAR acknowledged_date TIMESTAMP identified_at TIMESTAMP source VARCHAR modified_by_id VARCHAR body VARCHAR object_version BIGINT tags_json VARCHAR created_by_id VARCHAR custom_schema_fragments VARCHAR[] owned_by_ids VARCHAR[] identified_date TIMESTAMP is_deleted BOOLEAN title VARCHAR last_system_modification_version BIGINT impacted_customers VARCHAR[] target_close_date TIMESTAMP created_date TIMESTAMP reported_by VARCHAR custom_schema_fragment_ids VARCHAR[] related_doc_ids VARCHAR[]
Table name: system.article_views_and_votes_summary
Table schema: article_id VARCHAR record_date DATE account_id VARCHAR surface VARCHAR is_verified BOOLEAN total_views BIGINT total_duration_ms BIGINT unique_views BIGINT article_upvotes BIGINT article_downvotes BIGINT
Table name: system.dim_article
Table schema: stock_schema_fragment_id VARCHAR object_version BIGINT last_system_modification_version BIGINT modified_date TIMESTAMP authored_by_ids VARCHAR[] sync_metadata VARCHAR created_date TIMESTAMP owned_by_ids VARCHAR[] shared_with VARCHAR extracted_content VARCHAR[] external_source_data VARCHAR created_by_id VARCHAR modified_by_id VARCHAR subtype VARCHAR resource_json VARCHAR object_type VARCHAR operation VARCHAR tags_json VARCHAR custom_schema_fragment_ids VARCHAR[] status VARCHAR num_downvotes BIGINT title VARCHAR rank VARCHAR custom_fields VARCHAR display_id VARCHAR scope VARCHAR access_level BIGINT num_upvotes BIGINT applies_to_part_ids VARCHAR[] aliases VARCHAR[] id VARCHAR is_deleted BOOLEAN parent VARCHAR description VARCHAR type BIGINT published_date TIMESTAMP language VARCHAR
Table name: system.mobile_sessions_metadatas_v1
Table schema: session_id VARCHAR created_at TIMESTAMP version_key VARCHAR identifier VARCHAR network_operator VARCHAR network_type VARCHAR first_user_interaction BIGINT app_launch_time BIGINT app_launch_type VARCHAR device_manufacturer VARCHAR device_name VARCHAR app_version VARCHAR exception_type VARCHAR error_count BIGINT is_rage BIGINT ux_evaluation VARCHAR platform VARCHAR

Ensure at least two of them have multiple-table joins in the WHERE clause, and at least one JOINs three tables.

## Follow-Up: If Errors...

What instructions/guidelines would you provide, including any example code-snippets, to guide yourself to produce the correct query the very first time, for any other use-case?
Make the instructions/guidelines generic across any use-case, and concise/precise.

# Output

## Query 1: AWS cost by service and environment with monthly totals

```sql
SELECT
    service,
    env,
    DATE_TRUNC('month', usage_date) AS month,
    SUM(cost) AS total_cost
FROM
    memory.aws_daily_cost_v7
WHERE
    usage_date >= DATE '2023-01-01'
    AND usage_date < DATE '2023-07-01'
GROUP BY
    service, env, DATE_TRUNC('month', usage_date)
HAVING
    SUM(cost) > 1000
ORDER BY
    month, total_cost DESC
LIMIT 20;
```

### ERROR 1

Binder Error: Cannot compare values of type VARCHAR and type DATE - an explicit cast is required LINE 9: usage_date >= DATE '2023-01-01' ^

### Output 2

```sql
SELECT
    service,
    env,
    DATE_TRUNC('month', CAST(usage_date AS DATE)) AS month,
    SUM(cost) AS total_cost
FROM
    memory.aws_daily_cost_v7
WHERE
    CAST(usage_date AS DATE) >= DATE '2023-01-01'
    AND CAST(usage_date AS DATE) < DATE '2023-07-01'
GROUP BY
    service, env, DATE_TRUNC('month', CAST(usage_date AS DATE))
HAVING
    SUM(cost) > 1000
ORDER BY
    month, total_cost DESC
LIMIT 20;
```

### ERROR 2

Query executed, but no data

### Outpu 3: SUCCESS!

```sql
-- Check if there's any data in the table at all
SELECT COUNT(*) FROM memory.aws_daily_cost_v7;

-- Check the date range available in the table
SELECT MIN(usage_date), MAX(usage_date) FROM memory.aws_daily_cost_v7;

-- Check a sample of the date format
SELECT DISTINCT usage_date FROM memory.aws_daily_cost_v7 LIMIT 10;

-- Check if there are any entries with significant costs
SELECT MAX(cost) FROM memory.aws_daily_cost_v7;

-- Remove the HAVING clause to see if any data exists without the cost filter
SELECT
    service,
    env,
    DATE_TRUNC('month', CAST(usage_date AS DATE)) AS month,
    SUM(cost) AS total_cost
FROM
    memory.aws_daily_cost_v7
WHERE
    CAST(usage_date AS DATE) >= DATE '2023-01-01'
    AND CAST(usage_date AS DATE) < DATE '2023-07-01'
GROUP BY
    service, env, DATE_TRUNC('month', CAST(usage_date AS DATE))
ORDER BY
    total_cost DESC
LIMIT 20;
```

## Query 2: Compare OpenAI costs vs AWS costs per month (two-table join)

```sql
SELECT
    DATE_TRUNC('month', aws.usage_date) AS month,
    SUM(aws.cost) AS aws_total_cost,
    SUM(oai.amount) AS openai_total_cost,
    SUM(oai.amount) / NULLIF(SUM(aws.cost), 0) * 100 AS openai_percentage
FROM
    memory.aws_daily_cost_v7 aws
LEFT JOIN
    memory.openai_daily_costs_v3 oai
    ON DATE_TRUNC('day', aws.usage_date) = oai.usage_date
WHERE
    aws.usage_date >= DATE '2023-01-01'
GROUP BY
    DATE_TRUNC('month', aws.usage_date)
ORDER BY
    month;
```

### Error 1

Binder Error: No function matches the given name and argument types 'date_trunc(STRING_LITERAL, VARCHAR)'. You might need to add explicit type casts. Candidate functions: date_trunc(VARCHAR, TIMESTAMP) -> TIMESTAMP date_trunc(VARCHAR, DATE) -> TIMESTAMP date_trunc(VARCHAR, INTERVAL) -> INTERVAL LINE 10: ON DATE_TRUNC('day', aws.usage_date) = oai.usage_date WHERE aws.usage_date >= DATE '2023-01-01' GROUP BY DATE_TRUNC('month', aws.usage_date) ORDER BY month LIMIT 250... ^

### Output 2: SUCCESS

```sql
SELECT
    DATE_TRUNC('month', CAST(aws.usage_date AS DATE)) AS month,
    SUM(aws.cost) AS aws_total_cost,
    SUM(oai.amount) AS openai_total_cost,
    SUM(oai.amount) / NULLIF(SUM(aws.cost), 0) * 100 AS openai_percentage
FROM
    memory.aws_daily_cost_v7 aws
LEFT JOIN
    memory.openai_daily_costs_v3 oai
    ON DATE_TRUNC('day', CAST(aws.usage_date AS DATE)) = oai.usage_date
WHERE
    CAST(aws.usage_date AS DATE) >= DATE '2023-01-01'
GROUP BY
    DATE_TRUNC('month', CAST(aws.usage_date AS DATE))
ORDER BY
    month;
```

## Query 3: Article performance with author information (three-table join)

```sql
SELECT
    a.title,
    a.id AS article_id,
    a.created_date,
    a.num_upvotes - a.num_downvotes AS net_votes,
    SUM(avs.total_views) AS total_views,
    SUM(avs.unique_views) AS unique_views,
    AVG(avs.total_duration_ms) / 1000.0 AS avg_view_duration_seconds,
    i.title AS related_incident,
    i.severity_json
FROM
    system.dim_article a
JOIN
    system.article_views_and_votes_summary avs
    ON a.id = avs.article_id
LEFT JOIN
    system.dim_incident i
    ON i.id = ANY(a.applies_to_part_ids)
WHERE
    a.is_deleted = FALSE
    AND avs.record_date >= DATE '2023-01-01'
    AND a.status = 'published'
GROUP BY
    a.title, a.id, a.created_date, a.num_upvotes, a.num_downvotes, i.title, i.severity_json
ORDER BY
    total_views DESC
LIMIT 15;
```

### #rror 1

Not implemented Error: Cannot perform non-inner join on subquery!

### Output 2

```sql
WITH article_data AS (
    SELECT
        a.title,
        a.id AS article_id,
        a.created_date,
        a.num_upvotes - a.num_downvotes AS net_votes,
        a.applies_to_part_ids,
        SUM(avs.total_views) AS total_views,
        SUM(avs.unique_views) AS unique_views,
        AVG(avs.total_duration_ms) / 1000.0 AS avg_view_duration_seconds
    FROM
        system.dim_article a
    JOIN
        system.article_views_and_votes_summary avs
        ON a.id = avs.article_id
    WHERE
        a.is_deleted = FALSE
        AND avs.record_date >= DATE '2023-01-01'
        AND a.status = 'published'
    GROUP BY
        a.title, a.id, a.created_date, a.num_upvotes, a.num_downvotes, a.applies_to_part_ids
)
SELECT
    ad.title,
    ad.article_id,
    ad.created_date,
    ad.net_votes,
    ad.total_views,
    ad.unique_views,
    ad.avg_view_duration_seconds,
    i.title AS related_incident,
    i.severity_json
FROM
    article_data ad
LEFT JOIN
    system.dim_incident i
    ON i.id = ANY(ad.applies_to_part_ids)
ORDER BY
    ad.total_views DESC
LIMIT 15;
```

### Error 2

Not implemented Error: Cannot perform non-inner join on subquery!

### Output 3

```sql
-- First get the article performance data
WITH article_performance AS (
    SELECT
        a.title,
        a.id AS article_id,
        a.created_date,
        a.num_upvotes - a.num_downvotes AS net_votes,
        a.applies_to_part_ids,
        SUM(avs.total_views) AS total_views,
        SUM(avs.unique_views) AS unique_views,
        AVG(avs.total_duration_ms) / 1000.0 AS avg_view_duration_seconds
    FROM
        system.dim_article a
    JOIN
        system.article_views_and_votes_summary avs
        ON a.id = avs.article_id
    WHERE
        a.is_deleted = FALSE
        AND avs.record_date >= DATE '2023-01-01'
        AND a.status = 'published'
    GROUP BY
        a.title, a.id, a.created_date, a.num_upvotes, a.num_downvotes, a.applies_to_part_ids
),
-- Then flatten the array relationship to incidents
article_incidents AS (
    SELECT
        ap.article_id,
        unnest(ap.applies_to_part_ids) AS incident_id
    FROM article_performance ap
    WHERE ap.applies_to_part_ids IS NOT NULL
)
-- Finally join everything together
SELECT
    ap.title,
    ap.article_id,
    ap.created_date,
    ap.net_votes,
    ap.total_views,
    ap.unique_views,
    ap.avg_view_duration_seconds,
    i.title AS related_incident,
    i.severity_json
FROM
    article_performance ap
LEFT JOIN
    article_incidents ai ON ap.article_id = ai.article_id
LEFT JOIN
    system.dim_incident i ON ai.incident_id = i.id
ORDER BY
    ap.total_views DESC
LIMIT 15;
```

### Weeoe 3

Query executed, but no data

### Output 4

```sql
-- First, check if we have any articles that meet the basic criteria
SELECT
    COUNT(*) as article_count
FROM
    system.dim_article a
WHERE
    a.is_deleted = FALSE
    AND a.status = 'published';

-- Then check if the join with view data works
SELECT
    COUNT(*) as article_with_views_count
FROM
    system.dim_article a
JOIN
    system.article_views_and_votes_summary avs
    ON a.id = avs.article_id
WHERE
    a.is_deleted = FALSE
    AND avs.record_date >= DATE '2023-01-01'
    AND a.status = 'published';

-- Check basic article data without the incident join
SELECT
    a.title,
    a.id AS article_id,
    a.created_date,
    a.num_upvotes - a.num_downvotes AS net_votes,
    SUM(avs.total_views) AS total_views,
    SUM(avs.unique_views) AS unique_views,
    AVG(avs.total_duration_ms) / 1000.0 AS avg_view_duration_seconds
FROM
    system.dim_article a
JOIN
    system.article_views_and_votes_summary avs
    ON a.id = avs.article_id
WHERE
    a.is_deleted = FALSE
    AND avs.record_date >= DATE '2023-01-01'
    AND a.status = 'published'
GROUP BY
    a.title, a.id, a.created_date, a.num_upvotes, a.num_downvotes
ORDER BY
    total_views DESC
LIMIT 15;
```

### Error 4

<STILL NO DATA>

## Query 4: Email communication analysis by sender domain

### Output 1: SUCCESS!

```sql
SELECT
    SPLIT_PART(sender_address, '@', 2) AS sender_domain,
    COUNT(*) AS email_count,
    COUNT(DISTINCT sender_user_id) AS unique_senders,
    AVG(ARRAY_LENGTH(receiver_address, 1)) AS avg_recipients,
    MIN(created_date) AS first_contact,
    MAX(created_date) AS last_contact
FROM
    memory.email_and_linkedin_chats
WHERE
    sender_address LIKE '%@%'
    AND created_date >= TIMESTAMP '2023-01-01 00:00:00'
GROUP BY
    SPLIT_PART(sender_address, '@', 2)
HAVING
    COUNT(*) > 5
ORDER BY
    email_count DESC;
```

## Query 5: Mobile app performance analysis with crash rates

### Output 1

```sql
SELECT
    platform,
    app_version,
    COUNT(*) AS session_count,
    COUNT(DISTINCT identifier) AS user_count,
    AVG(app_launch_time) / 1000.0 AS avg_launch_time_sec,
    SUM(error_count) AS total_errors,
    SUM(error_count)::FLOAT / COUNT(*) AS errors_per_session,
    SUM(is_rage) AS rage_count,
    (SUM(is_rage)::FLOAT / COUNT(*)) * 100 AS rage_percentage
FROM
    system.mobile_sessions_metadatas_v1
WHERE
    created_at >= TIMESTAMP '2023-04-01 00:00:00'
    AND created_at < TIMESTAMP '2023-07-01 00:00:00'
GROUP BY
    platform, app_version
HAVING
    COUNT(*) >= 50
ORDER BY
    platform,
    app_version;
```

### Error 1

Query executed, but no data

### Output 2: SUCCESS

```sql
SELECT
    platform,
    app_version,
    COUNT(*) AS session_count,
    COUNT(DISTINCT identifier) AS user_count,
    AVG(app_launch_time) / 1000.0 AS avg_launch_time_sec,
    SUM(error_count) AS total_errors,
    SUM(error_count)::FLOAT / NULLIF(COUNT(*), 0) AS errors_per_session,
    SUM(CASE WHEN is_rage = TRUE THEN 1 ELSE 0 END) AS rage_count,
    (SUM(CASE WHEN is_rage = TRUE THEN 1 ELSE 0 END)::FLOAT / NULLIF(COUNT(*), 0)) * 100 AS rage_percentage
FROM
    system.mobile_sessions_metadatas_v1
WHERE
    created_at >= CURRENT_DATE - INTERVAL '90 days'
GROUP BY
    platform, app_version
HAVING
    COUNT(*) >= 10
ORDER BY
    platform,
    session_count DESC;
```

## Query 6: User engagement statistics with verification status

### Output 1: SUCCESS

```sql
SELECT
    DATE_TRUNC('week', created_at) AS week,
    is_verified,
    COUNT(DISTINCT rev_oid) AS active_users,
    SUM(total_user_sessions) AS total_sessions,
    SUM(total_session_length) / 3600.0 AS total_hours_spent,
    SUM(total_session_length) / SUM(total_user_sessions) AS avg_session_length_sec,
    SUM(total_events) AS total_events,
    SUM(total_events)::FLOAT / SUM(total_user_sessions) AS events_per_session
FROM
    system.user_sessions_track_events_summary_v2
WHERE
    created_at >= TIMESTAMP '2023-01-01 00:00:00'
GROUP BY
    DATE_TRUNC('week', created_at),
    is_verified
ORDER BY
    week DESC,
    is_verified;
```

## Query 7: AWS and OpenAI cost analysis by project and region (two-table join)

### Output 1

```sql
WITH aws_costs AS (
    SELECT
        region,
        DATE_TRUNC('month', usage_date) AS month,
        SUM(cost) AS total_aws_cost
    FROM
        memory.aws_daily_cost_v7
    WHERE
        service LIKE '%Compute%'
        AND usage_date >= DATE '2023-01-01'
    GROUP BY
        region, DATE_TRUNC('month', usage_date)
),
openai_costs AS (
    SELECT
        project_name,
        DATE_TRUNC('month', usage_date) AS month,
        SUM(amount) AS total_openai_cost
    FROM
        memory.openai_daily_costs_v3
    WHERE
        usage_date >= DATE '2023-01-01'
    GROUP BY
        project_name, DATE_TRUNC('month', usage_date)
)
SELECT
    a.region,
    o.project_name,
    a.month,
    a.total_aws_cost,
    o.total_openai_cost,
    (a.total_aws_cost + COALESCE(o.total_openai_cost, 0)) AS combined_cost
FROM
    aws_costs a
JOIN
    openai_costs o
    ON a.month = o.month
WHERE
    a.total_aws_cost > 500
ORDER BY
    a.month DESC,
    combined_cost DESC;
```

### ERROR 1

Binder Error: Cannot compare values of type VARCHAR and type DATE - an explicit cast is required LINE 10: AND usage_date >= DATE '2023-01-01' ^

### Output 2: SUCCESS

```sql
WITH aws_costs AS (
    SELECT
        region,
        DATE_TRUNC('month', CAST(usage_date AS DATE)) AS month,
        SUM(cost) AS total_aws_cost
    FROM
        memory.aws_daily_cost_v7
    WHERE
        service LIKE '%Compute%'
        AND CAST(usage_date AS DATE) >= DATE '2023-01-01'
    GROUP BY
        region, DATE_TRUNC('month', CAST(usage_date AS DATE))
),
openai_costs AS (
    SELECT
        project_name,
        DATE_TRUNC('month', CAST(usage_date AS DATE)) AS month,
        SUM(amount) AS total_openai_cost
    FROM
        memory.openai_daily_costs_v3
    WHERE
        CAST(usage_date AS DATE) >= DATE '2023-01-01'
    GROUP BY
        project_name, DATE_TRUNC('month', CAST(usage_date AS DATE))
)
SELECT
    a.region,
    o.project_name,
    a.month,
    a.total_aws_cost,
    o.total_openai_cost,
    (a.total_aws_cost + COALESCE(o.total_openai_cost, 0)) AS combined_cost
FROM
    aws_costs a
JOIN
    openai_costs o
    ON a.month = o.month
WHERE
    a.total_aws_cost > 500
ORDER BY
    a.month DESC,
    combined_cost DESC;
```

## Query 8: Incident resolution time analysis by severity

### Output 1

```sql
SELECT
    JSON_EXTRACT_PATH_TEXT(severity_json, 'value') AS severity,
    COUNT(*) AS incident_count,
    AVG(EXTRACT(EPOCH FROM (resolved_at - identified_at))/3600) AS avg_resolution_hours,
    MIN(EXTRACT(EPOCH FROM (resolved_at - identified_at))/3600) AS min_resolution_hours,
    MAX(EXTRACT(EPOCH FROM (resolved_at - identified_at))/3600) AS max_resolution_hours,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY EXTRACT(EPOCH FROM (resolved_at - identified_at))/3600) AS median_resolution_hours,
    AVG(ARRAY_LENGTH(stakeholders, 1)) AS avg_stakeholders_involved
FROM
    system.dim_incident
WHERE
    resolved_at IS NOT NULL
    AND identified_at IS NOT NULL
    AND created_date >= TIMESTAMP '2023-01-01 00:00:00'
    AND is_deleted = FALSE
GROUP BY
    JSON_EXTRACT_PATH_TEXT(severity_json, 'value')
ORDER BY
    avg_resolution_hours DESC;
```

### Error 1

Binder Error: Referenced column "stakeholders" not found in FROM clause! Candidate bindings: "dim_incident.state" LINE 8: AVG(ARRAY_LENGTH(stakeholders, 1)) AS avg_stakeholders_involved FROM system.dim_incident WHERE resolved_at IS NOT NULL AND identified_at IS NOT NULL AND created_date >= TIMESTAMP '2023-01-01 00:00:00' AND is_deleted = FALSE GROUP BY JSON_EXTRACT_PATH_TEXT(severity_json, 'value') ORDER BY avg_resolution_hours DESC LIMIT 250... ^

### Output 2

```sql
SELECT
JSON_EXTRACT_PATH_TEXT(severity_json, 'value') AS severity,
-- Replace this line with a column that actually exists
-- AVG(ARRAY_LENGTH(stakeholders, 1)) AS avg_stakeholders_involved,
-- For example, if the column is actually called 'incident_stakeholders'
AVG(ARRAY_LENGTH(incident_stakeholders, 1)) AS avg_stakeholders_involved,
-- Add other calculations you might need
AVG(EXTRACT(EPOCH FROM (resolved_at - identified_at))/3600) AS avg_resolution_hours
FROM
system.dim_incident
WHERE
resolved_at IS NOT NULL
AND identified_at IS NOT NULL
AND created_date >= TIMESTAMP '2023-01-01 00:00:00'
AND is_deleted = FALSE
GROUP BY
JSON_EXTRACT_PATH_TEXT(severity_json, 'value')
ORDER BY
avg_resolution_hours DESC
LIMIT 250
```

### Error 2

Binder Error: Referenced column "incident_stakeholders" not found in FROM clause! Candidate bindings: "dim_incident.title" LINE 6: AVG(ARRAY_LENGTH(incident_stakeholders, 1)) AS avg_stakeholders_involved, -- Add other calculations you might need AVG(EXTRACT(EPOCH FROM (resolved_at - identified_at))/3600) AS avg_resolution_hours FROM system.dim_incident WHERE resolved_at IS NOT NULL AND identified_at IS NOT NULL AND created_date >= TIMESTAMP '2023-01-01 00:00:00' AND is_deleted = FALSE GROUP BY JSON_EXTRACT_PATH_TEXT(severity_json, 'value') ORDER BY avg_resolution_hours DESC LIMIT 250... ^

### Output 3

```sql
SELECT
    JSON_EXTRACT_PATH_TEXT(severity_json, 'value') AS severity,
    -- Temporarily remove the stakeholder calculation
    -- We'll add it back once we know the correct column name
    AVG(EXTRACT(EPOCH FROM (resolved_at - identified_at))/3600) AS avg_resolution_hours,
    COUNT(*) AS incident_count
FROM
    system.dim_incident
WHERE
    resolved_at IS NOT NULL
    AND identified_at IS NOT NULL
    AND created_date >= TIMESTAMP '2023-01-01 00:00:00'
    AND is_deleted = FALSE
GROUP BY
    JSON_EXTRACT_PATH_TEXT(severity_json, 'value')
ORDER BY
    avg_resolution_hours DESC
LIMIT 250;
```

### Error 3: NO RESULT

Query executed, but no data

## Query 9: Article engagement by article type with user verification segmentation

### Output 1

```sql
SELECT
    a.type,
    a.access_level,
    avs.is_verified,
    COUNT(DISTINCT a.id) AS article_count,
    SUM(avs.total_views) AS total_views,
    SUM(avs.unique_views) AS unique_views,
    SUM(avs.article_upvotes) AS total_upvotes,
    SUM(avs.article_downvotes) AS total_downvotes,
    CASE
        WHEN SUM(avs.article_upvotes + avs.article_downvotes) > 0
        THEN SUM(avs.article_upvotes)::FLOAT / SUM(avs.article_upvotes + avs.article_downvotes)
        ELSE 0
    END AS positive_rating_ratio
FROM
    system.dim_article a
JOIN
    system.article_views_and_votes_summary avs
    ON a.id = avs.article_id
WHERE
    avs.record_date >= DATE '2023-01-01'
    AND a.is_deleted = FALSE
    AND a.status = 'published'
GROUP BY
    a.type, a.access_level, avs.is_verified
HAVING
    COUNT(DISTINCT a.id) >= 5
ORDER BY
    total_views DESC,
    a.type,
    avs.is_verified;
```

### Error 1

Query executed, but no data

### Output 2

```sql
SELECT
    a.type,
    a.access_level,
    avs.is_verified,
    COUNT(DISTINCT a.id) AS article_count,
    SUM(avs.total_views) AS total_views,
    SUM(avs.unique_views) AS unique_views,
    SUM(avs.article_upvotes) AS total_upvotes,
    SUM(avs.article_downvotes) AS total_downvotes,
    CASE
        WHEN SUM(avs.article_upvotes + avs.article_downvotes) > 0
        THEN SUM(avs.article_upvotes)::FLOAT / SUM(avs.article_upvotes + avs.article_downvotes)
        ELSE 0
    END AS positive_rating_ratio
FROM
    system.dim_article a
JOIN
    system.article_views_and_votes_summary avs
    ON a.id = avs.article_id
WHERE
    avs.record_date >= DATE '2022-01-01'  -- Extended date range further back
    AND a.is_deleted = FALSE
    AND a.status = 'published'
GROUP BY
    a.type, a.access_level, avs.is_verified
HAVING
    COUNT(DISTINCT a.id) >= 3  -- Reduced minimum article threshold
ORDER BY
    total_views DESC,
    a.type,
    avs.is_verified;
```

### Error 2

Query executed, but no data

### Output 3

```sql
SELECT
    a.type,
    a.access_level,
    COUNT(DISTINCT a.id) AS article_count,
    SUM(COALESCE(avs.total_views, 0)) AS total_views,
    SUM(COALESCE(avs.unique_views, 0)) AS unique_views,
    SUM(COALESCE(avs.article_upvotes, 0)) AS total_upvotes,
    SUM(COALESCE(avs.article_downvotes, 0)) AS total_downvotes,
    CASE
        WHEN SUM(COALESCE(avs.article_upvotes, 0) + COALESCE(avs.article_downvotes, 0)) > 0
        THEN SUM(COALESCE(avs.article_upvotes, 0))::FLOAT / SUM(COALESCE(avs.article_upvotes, 0) + COALESCE(avs.article_downvotes, 0))
        ELSE 0
    END AS positive_rating_ratio
FROM
    system.dim_article a
LEFT JOIN
    system.article_views_and_votes_summary avs
    ON a.id = avs.article_id
WHERE
    a.is_deleted = FALSE
    AND a.status = 'published'
GROUP BY
    a.type, a.access_level
ORDER BY
    total_views DESC,
    a.type;
```

## Query 10: Cross-domain analysis of user engagement, article usage, and costs (three-table join)

### Output 1

```sql
Binder Error: Cannot compare values of type VARCHAR and type DATE - an explicit cast is required LINE 37: usage_date >= DATE '2023-01-01' ^
```

### Error 1

Binder Error: Cannot compare values of type VARCHAR and type DATE - an explicit cast is required LINE 37: usage_date >= DATE '2023-01-01' ^

### Output 2: SUCCESS

```sql
WITH user_activity AS (
    SELECT
        DATE_TRUNC('month', created_at) AS month,
        is_verified,
        COUNT(DISTINCT rev_oid) AS active_users,
        SUM(total_events) AS total_events
    FROM
        system.user_sessions_track_events_summary_v2
    WHERE
        created_at >= TIMESTAMP '2023-01-01 00:00:00'
    GROUP BY
        DATE_TRUNC('month', created_at),
        is_verified
),
article_usage AS (
    SELECT
        DATE_TRUNC('month', record_date) AS month,
        is_verified,
        COUNT(DISTINCT article_id) AS viewed_articles,
        SUM(total_views) AS total_views,
        SUM(total_duration_ms) / 1000.0 / 3600 AS total_hours_spent
    FROM
        system.article_views_and_votes_summary
    WHERE
        record_date >= DATE '2023-01-01'
    GROUP BY
        DATE_TRUNC('month', record_date),
        is_verified
),
monthly_costs AS (
    SELECT
        DATE_TRUNC('month', usage_date::DATE) AS month,
        SUM(cost) AS aws_cost
    FROM
        memory.aws_daily_cost_v7
    WHERE
        usage_date::DATE >= DATE '2023-01-01'
    GROUP BY
        DATE_TRUNC('month', usage_date::DATE)
)
SELECT
    ua.month,
    ua.is_verified,
    ua.active_users,
    ua.total_events,
    ua.total_events / NULLIF(ua.active_users, 0) AS events_per_user,
    au.viewed_articles,
    au.total_views,
    au.total_views / NULLIF(ua.active_users, 0) AS views_per_user,
    au.total_hours_spent,
    au.total_hours_spent / NULLIF(ua.active_users, 0) AS hours_per_user,
    mc.aws_cost,
    mc.aws_cost / NULLIF(ua.active_users, 0) AS cost_per_user
FROM
    user_activity ua
JOIN
    article_usage au
    ON ua.month = au.month AND ua.is_verified = au.is_verified
JOIN
    monthly_costs mc
    ON ua.month = mc.month
ORDER BY
    ua.month DESC,
    ua.is_verified;
```
